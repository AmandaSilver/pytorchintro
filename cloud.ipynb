{"cells":[{"cell_type":"markdown","metadata":{},"source":"# To The Cloud (AND BEYOND)\nNow that we have a good idea on how to solve the digit problem, it's time to move the training part to the cloud (again, there's no need to with this problem but for other problems we test locally to test things out on a subset of our data and move to the cloud to work on the whole lot).\n\nLet's set some things up!\n\nThe first thing you might need to do is ensure that our `azureml.core` package is installed in the notebook environment. If you are using Azure Notebooks there's an easy two step process to get going."},{"cell_type":"markdown","metadata":{},"source":"## Adding Dependencies in Azure Notebooks\nClick on the \"Project Settings\"\n\n![Project Setings](https://raw.githubusercontent.com/sethjuarez/pytorchintro/master/images/project_settings.png)\n\nNext, select the \"Environments\" tab, choose \"Python 3.6\", and finally select the corresponding `requirements.txt` file.\n\n![Settings](https://raw.githubusercontent.com/sethjuarez/pytorchintro/master/images/settings.png)\n\nAfter those steps you should be good to go!\n\nNOTE: If you have an issue after setting up the project settings. In the notebook make sure the kernel is set to python 3.6 by doing the following: Select Kernel> Change Kernel >  Python 3.6\n"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Azure ML SDK Version:  1.0.21\n"}],"source":"import json\nimport time\nimport azureml\nfrom azureml.core.model import Model\nfrom azureml.core import Workspace, Run, Experiment\nfrom azureml.core.runconfig import RunConfiguration\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\nfrom azureml.train.dnn import PyTorch\nfrom azureml.widgets import RunDetails\nfrom torchvision import datasets, transforms\n\nprint(\"Azure ML SDK Version: \", azureml.core.VERSION)"},{"cell_type":"markdown","metadata":{},"source":"# Setting up Azure Machine Learning service\nThe first thing you need to do is create an Azure Machine Learning workspace. There are [docs](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-get-started#create-a-workspace) on how to do that. If you're a command line type person, I have an [example](https://github.com/sethjuarez/workspacestarter) of how you can set it up using the Azure CLI. Once you've set the project up fill in the appropriate settings for your workspace by uncommenting the code below to write out the config file. Once the config file has been written out, you can load the workspace programmatically like I've done below."},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Found the config file in: c:\\projects\\pytorchintro\\aml_config\\config.json\n"}],"source":"##use this code to set up config file\n#subscription_id ='<SUB_ID>'\n#resource_group ='<RESOURCE_GROUP>'\n#workspace_name = '<WORKSPACE>'\n\n#try:\n#    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n#    ws.write_config()\n#    print('Workspace configuration succeeded. You are all set!')\n#except:\n#    print('Workspace not found. TOO MANY ISSUES!!!')\n\n##once you run the above code once, you can use the written config\nws = Workspace.from_config()"},{"cell_type":"markdown","metadata":{},"source":"# Cloud Compute\nNext we need to define a compute target for your experiment. Since this is a brand new workspace, feel free to change the name of your cluster (I called my `racer`). The code below tries to get a reference to my cluster but if it doesn't exist, it creates it for me. If you're creating a cluster this might take a bit of time. Also, please turn these off when you're done (in fact consider setting the `min_nodes` to 0 so the cluster turns off automatically if it's idle for too long) - I don't want you to get an unexpected bill."},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Found existing compute target \"gandalf\"\n"}],"source":"cluster = 'gandalf'\ntry:\n    compute = ComputeTarget(workspace=ws, name=cluster)\n    print('Found existing compute target \"{}\"'.format(cluster))\nexcept ComputeTargetException:\n    print('Creating new compute target \"{}\"...'.format(cluster))\n    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', min_nodes=1, max_nodes=6)\n    compute = ComputeTarget.create(ws, cluster, compute_config)\n    compute.wait_for_completion(show_output=True)"},{"cell_type":"markdown","metadata":{},"source":"# Time to Experiment\nOnce our compute target has been set up it's time to package up our tiny notebook from last time into a single script that a remote compute environment can run. I've taken the time to [do that for you](train.py). In fact, if you look at the file you will see all of the exact same concepts we learned from the previous notebook (it's almost exactly the same but I have added additional things to make it easier to pass things into the script).\n\nIn AzureML service there is a concept of an experiment. For every experiment you can have multiple runs. In this case I'm using an `Estimator` object that defines how the experiment should run.\n\n### Don't read this if you don't care what we do in the background\nIn the background the estimator is basically a definition of sorts for a docker image that will house your experiment. The best part about all of this is that irrespective of what you use for your experiment (a crazy custom version of TensorFlow or something) it should always run - it's a container after all. It's pretty slick.\n\n### Back to the regular stuff\nOnce we submit our estimator to be run on AzureML service, it copies the contents of the current directory and packages them up to run in our new container (well, it will upload everything with the exception of anything you put describe in the [.amlignore](https://github.com/sethjuarez/pytorchintro/blob/master/.amlignore) file).\n\nNotice also that since I'm using `argparse` I can specify external parameters to the training script as part of the estimator definition.\n\nLet's run the next three lines to see what happens!"},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":"# Create and run experiment\nmnist = Experiment(ws, 'pytorchmnist')\n\n# script parameters\nscript_params={\n    '--epochs': 5,\n    '--batch': 100,\n    '--lr': .001,\n    '--model': 'cnn'\n}\n\n# Create Estimator\nestimator = PyTorch(source_directory='.',\n                       compute_target=compute, \n                       entry_script='train.py',\n                       script_params=script_params,\n                       use_gpu=True)\n\nrun = mnist.submit(estimator)"},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/html":"<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>pytorchmnist</td><td>pytorchmnist_1569761135_c4c1c5f3</td><td>azureml.scriptrun</td><td>Preparing</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/91d27443-f037-45d9-bb0c-428256992df6/resourceGroups/Robots/providers/Microsoft.MachineLearningServices/workspaces/hal/experiments/pytorchmnist/runs/pytorchmnist_1569761135_c4c1c5f3\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>","text/plain":"Run(Experiment: pytorchmnist,\nId: pytorchmnist_1569761135_c4c1c5f3,\nType: azureml.scriptrun,\nStatus: Preparing)"},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":"run"},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41dac9cfc0424f4bbc775fbf348581e5","version_major":2,"version_minor":0},"text/plain":"_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"},"metadata":{},"output_type":"display_data"}],"source":"RunDetails(run).show()"},{"cell_type":"markdown","metadata":{},"source":"If everything wen't to plan you should see something like this:\n\n![AzureML Run](https://raw.githubusercontent.com/sethjuarez/pytorchintro/master/images/run_widget.png)\n\nNotice that indeed the loss function decreased (on average) over time and the accuracy of the model increased! Try playing around with the `learning_rate` by changing the parameters. Better yet, you can have [AzureML service sweep accross a whole bunch of parameters](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters) for you!\n\nNow for the question of how I got those wonderful charts to show up. This is where AzureML service starts to actually add value to what you were already doing. With a [few](https://github.com/sethjuarez/pytorchintro/blob/master/train.py#L156-L166) [strategically](https://github.com/sethjuarez/pytorchintro/blob/master/train.py#L121-L122) [placed](https://github.com/sethjuarez/pytorchintro/blob/master/train.py#L142-L143) log statements AzureML service was able to create this output. In fact, if a value is logged more than once it automatically creates charts instead of items in a table."},{"cell_type":"markdown","metadata":{},"source":["# The Model\n","Once the training is all done and you're satisfied with the output, you can actually peruse the ouput of all of the runs for a given experiment and promote it to an \"official\" workspace model. This is an awesome feature because the important files (i.e. the model that will make us zillionaires) are usually sitting on the computer some dude named Jeff. Also, many people don't even version models nowadays - running the code below will!"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":"['azureml-logs/20_image_build_log.txt',\n 'azureml-logs/55_azureml-execution-tvmps_82fc65d93e095994390fe4dd420181f16a0594c217a69c351c9fbafcbd22a60d_d.txt',\n 'azureml-logs/65_job_prep-tvmps_82fc65d93e095994390fe4dd420181f16a0594c217a69c351c9fbafcbd22a60d_d.txt',\n 'azureml-logs/70_driver_log.txt',\n 'azureml-logs/75_job_post-tvmps_82fc65d93e095994390fe4dd420181f16a0594c217a69c351c9fbafcbd22a60d_d.txt',\n 'logs/azureml/115_azureml.log',\n 'logs/azureml/azureml.log',\n 'outputs/model.onnx',\n 'outputs/model.pth']"},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":"run.get_file_names()"},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Registering model PyTorchMNIST\n"}],"source":"model_file = 'outputs/model.pth'\nrun.download_file(name=model_file, output_file_path='model.pth')\nmodel = Model.register(ws, model_name='PyTorchMNIST', model_path='model.pth', \n                       description='CNN PyTorch Model')"},{"cell_type":"markdown","metadata":{},"source":"# The Image\nNow that we have the model, if we want to use it in production we need to define how one should use the model. This is sometimes called scoring or inferencing. For AzureML service we are basically looking for two functions:\n1. `init()`, and\n2. `run(raw)` which takes in a json string and returns a prediction\nFirst thing's first though - we need to describe the environment where the scoring script will live and package it up into an environment file."},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Writing out pytorchmnist.yml\nDone!\n"}],"source":"myenv = CondaDependencies()\nmyenv.add_pip_package('numpy')\nmyenv.add_pip_package('torch')\nwith open('pytorchmnist.yml','w') as f:\n    print('Writing out {}'.format('pytorchmnist.yml'))\n    f.write(myenv.serialize_to_string())\n    print('Done!')"},{"cell_type":"markdown","metadata":{},"source":"Next we need to tell AzureML service the location of the scoring script. I have taken the liberty, dear reader, to [create that for you](score.py). Looking through the file you should be able to easily find both the `init()` and `run(raw)` methods. You can also run the file locally to make sure it is doing the right thing.\n\nNow that we have everything let's create an image!\n\n### Don't read this if you don't want to know what is happening in the background\nWhat we basically do is create a docker image from your definition and push it up to the an Azure Container Registry that belogns to the Workspace.\n\n**NOTE** This takes a while"},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Creating image\nRunning................................................\nSucceededImage creation operation finished for image pytorchmnist:3, operation \"Succeeded\"\n"}],"source":"from azureml.core.image import ContainerImage, Image\n\n# create image\nimage_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n                                runtime=\"python\", \n                                conda_file=\"pytorchmnist.yml\")\n\nimage = Image.create(ws, 'pytorchmnist', [model], image_config)\nimage.wait_for_creation(show_output=True)"},{"cell_type":"markdown","metadata":{},"source":"# Deploy!!\nYou could have certainly stopped with creating the image and moving the rest of the deployment process to something like Azure Pipelines. If you want to continue to deploy this service to the Workspace, this is how you do it."},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Deleting prior pytorchmnist-svc deployment\nCreating service\nRunning.........................\nSucceededACI service creation operation finished, operation \"Succeeded\"\nhttp://7a2c4886-87e9-4f6f-a8fd-feff636afab0.westus2.azurecontainer.io/score\n"}],"source":"from azureml.core.webservice import Webservice, AciWebservice\n\nservice_name = 'pytorchmnist-svc'\n\n# check for existing service\nsvcs = [svc for svc in Webservice.list(ws) if svc.name==service_name]\nif len(svcs) == 1:\n    print('Deleting prior {} deployment'.format(service_name))\n    svcs[0].delete()\n\n# create service\naciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                                            memory_gb=1, \n                                            description='simple MNIST digit detection')\nservice = Webservice.deploy_from_image(workspace=ws, \n                                    image=image, \n                                    name=service_name, \n                                    deployment_config=aciconfig)\nservice.wait_for_deployment(show_output=True)\nprint(service.scoring_uri)"},{"cell_type":"markdown","metadata":{},"source":"You have the option of pushing the image to ACI or even a workspace Kubernetes cluster.\n\nSometimes things go wrong....... If it does for you run the code below to see the actual [logs](deploy.log)!"},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":"with open('deploy.log','w') as f:\n    f.write(service.get_logs())"},{"cell_type":"markdown","metadata":{},"source":"# Running Service\nIT'S ALIVE!!! Let's see if it does sensible things. We will load up the test data from before so we can try random numbers."},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"10000\n"}],"source":"digits = datasets.MNIST('data', train=False, download=True,\n                        transform=transforms.Compose([\n                            transforms.ToTensor(),\n                            transforms.Lambda(lambda x: x.reshape(28*28))\n                        ])\n                     )\nprint(len(digits))"},{"cell_type":"markdown","metadata":{},"source":"You can basically choose any number as an index up to 60,000 (well, one less). Try out a couple to see how the service does!"},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":"<matplotlib.image.AxesImage at 0x2ce141fcc88>"},"execution_count":27,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"252.018125pt\" version=\"1.1\" viewBox=\"0 0 255.065 252.018125\" width=\"255.065pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 252.018125 \r\nL 255.065 252.018125 \r\nL 255.065 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 228.14 \r\nL 244.365 228.14 \r\nL 244.365 10.7 \r\nL 26.925 10.7 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pac7039ec5a)\">\r\n    <image height=\"218\" id=\"image3d826ad605\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-10.14\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m62b414a1d6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m62b414a1d6\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(27.626607 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m62b414a1d6\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(66.455179 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m62b414a1d6\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(102.1025 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m62b414a1d6\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(140.931071 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m62b414a1d6\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(179.759643 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m62b414a1d6\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(218.588214 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mfc2f7988a6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mfc2f7988a6\" y=\"14.582857\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 18.382076)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mfc2f7988a6\" y=\"53.411429\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(13.5625 57.210647)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mfc2f7988a6\" y=\"92.24\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 96.039219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mfc2f7988a6\" y=\"131.068571\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 134.86779)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mfc2f7988a6\" y=\"169.897143\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 173.696362)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mfc2f7988a6\" y=\"208.725714\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 212.524933)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 228.14 \r\nL 26.925 10.7 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 244.365 228.14 \r\nL 244.365 10.7 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 228.14 \r\nL 244.365 228.14 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 10.7 \r\nL 244.365 10.7 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pac7039ec5a\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"10.7\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":"import torch\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nX, Y = digits[20]\nX = X * 255\nplt.imshow(255 - X.reshape(28,28), cmap='gray')"},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,31,140,193,44,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,146,240,254,254,228,48,77,46,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,43,230,254,254,254,254,254,241,254,197,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,130,254,254,254,239,252,254,254,254,254,237,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,154,254,254,249,104,71,198,254,254,254,234,57,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,173,252,252,206,51,120,215,254,254,254,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,112,254,254,215,87,247,254,254,254,254,254,217,31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,231,254,254,254,254,254,236,128,196,254,254,119,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,197,254,254,245,238,131,17,46,247,254,199,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,92,88,40,0,0,12,173,254,242,38,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,95,254,254,155,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,210,254,225,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,197,254,254,99,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,34,242,254,179,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,27,223,254,225,30,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,77,254,255,127,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,54,238,254,248,53,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,183,254,254,231,41,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,113,254,254,230,48,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,110,239,126,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n"}],"source":"# This is a string representation of the image we will POST to the endpoint\nimage_str = ','.join(map(str, X.int().tolist()))\nprint(image_str)"},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"http://7a2c4886-87e9-4f6f-a8fd-feff636afab0.westus2.azurecontainer.io/score\n"},{"data":{"text/plain":"{'time': 0.003937,\n 'prediction': 9,\n 'scores': [7.555271408499209e-10,\n  7.813295788139385e-09,\n  3.864849702495121e-07,\n  9.322468395112082e-05,\n  0.0001763391774147749,\n  1.421677325197379e-06,\n  8.263524955455515e-13,\n  0.0029347348026931286,\n  3.161542190355249e-05,\n  0.9967622756958008]}"},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":"import json\nimport requests\nservice_url = service.scoring_uri\nprint(service_url)\nr = requests.post(service_url, json={'image': image_str })\nr.json()"},{"cell_type":"markdown","metadata":{},"source":["# Final Thoughts\n","Hopefully this little journey was helpful! My goal is to show you that tha basics of Machine Learning are not all that bad. If you have any comments, suggestions, or something does not make sense make sure to drop me a line!"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}